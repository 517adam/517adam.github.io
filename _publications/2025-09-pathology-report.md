---
title: "Pathology Report Generation via Multi-modal Learning"
collection: publications
permalink: /publication/2025-09-pathology-report
excerpt: 'Proposed a novel multi-modal framework to automatically generate pathology reports from Whole Slide Images (WSI).'
date: 2025-09-01
venue: 'Research Assistant, HKUST Smart Lab'
paperurl: ''
citation: 'Yuanzhong Chen. (2025). "Pathology Report Generation via Multi-modal Learning". Research Assistant, HKUST Smart Lab.'
---
**Role:** Research Assistant, Supervised by Prof. Hao Chen

**Description:**
* Proposed a novel multi-modal framework to automatically generate pathology reports from Whole Slide Images (WSI).
* Developing a two-stage training pipeline for pathology report generation, leveraging a highly structured, high-quality dataset to enhance generation accuracy.
* Addressed the scarcity of high-quality paired WSI-report datasets by constructing a large-scale instruction-tuning dataset.
* Designed a modality-alignment algorithm to enhance consistency between visual features and text descriptions, and proposed a disentanglement method to decouple template artifacts from diagnostic information.
* Leveraged State-of-the-Art Vision-Language Models (VLMs) to assist pathologists, targeting measurable improvements in clinical workflow efficiency.
